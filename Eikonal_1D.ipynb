{"cells":[{"cell_type":"markdown","metadata":{"id":"Je95UkAAeSz3"},"source":["The equation we are testing is\n","\n","$$\n","\\begin{cases}\n","|u'(x)|= 1, \\qquad\\text{for}\\; -1<x<1,\\\\\n","u(-1) = u(1) = 0.\n","\\end{cases}\n","$$ \n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oqyi5e3sePDl"},"outputs":[],"source":["# Import libraries\n","from numpy import linalg\n","import pandas as pd\n","import numpy as np\n","import math\n","# !pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","\n","import torch.nn.init as init\n","from torch import autograd\n","\n","from torch import nn, optim\n","from time import time"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UMTkPFHHFihK"},"outputs":[],"source":["eps = 0.0001\n","def u_star_func(x):\n","    x = x[1:-1]\n","    result = 1-np.abs(x) + eps*(np.exp(-1/eps) - np.exp(-1/eps*np.abs(x)))\n","    return np.hstack((0,result,0))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LBN2LBiGxH2M","outputId":"4906d6f8-5fd2-49c4-a1e2-d1fb9d2f9646","executionInfo":{"status":"ok","timestamp":1644904456323,"user_tz":-60,"elapsed":13,"user":{"displayName":"Thu Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64","userId":"04714273295929622355"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-1.0000e+00, -9.8000e-01, -9.6000e-01, -9.4000e-01, -9.2000e-01,\n","        -9.0000e-01, -8.8000e-01, -8.6000e-01, -8.4000e-01, -8.2000e-01,\n","        -8.0000e-01, -7.8000e-01, -7.6000e-01, -7.4000e-01, -7.2000e-01,\n","        -7.0000e-01, -6.8000e-01, -6.6000e-01, -6.4000e-01, -6.2000e-01,\n","        -6.0000e-01, -5.8000e-01, -5.6000e-01, -5.4000e-01, -5.2000e-01,\n","        -5.0000e-01, -4.8000e-01, -4.6000e-01, -4.4000e-01, -4.2000e-01,\n","        -4.0000e-01, -3.8000e-01, -3.6000e-01, -3.4000e-01, -3.2000e-01,\n","        -3.0000e-01, -2.8000e-01, -2.6000e-01, -2.4000e-01, -2.2000e-01,\n","        -2.0000e-01, -1.8000e-01, -1.6000e-01, -1.4000e-01, -1.2000e-01,\n","        -1.0000e-01, -8.0000e-02, -6.0000e-02, -4.0000e-02, -2.0000e-02,\n","         8.8818e-16,  2.0000e-02,  4.0000e-02,  6.0000e-02,  8.0000e-02,\n","         1.0000e-01,  1.2000e-01,  1.4000e-01,  1.6000e-01,  1.8000e-01,\n","         2.0000e-01,  2.2000e-01,  2.4000e-01,  2.6000e-01,  2.8000e-01,\n","         3.0000e-01,  3.2000e-01,  3.4000e-01,  3.6000e-01,  3.8000e-01,\n","         4.0000e-01,  4.2000e-01,  4.4000e-01,  4.6000e-01,  4.8000e-01,\n","         5.0000e-01,  5.2000e-01,  5.4000e-01,  5.6000e-01,  5.8000e-01,\n","         6.0000e-01,  6.2000e-01,  6.4000e-01,  6.6000e-01,  6.8000e-01,\n","         7.0000e-01,  7.2000e-01,  7.4000e-01,  7.6000e-01,  7.8000e-01,\n","         8.0000e-01,  8.2000e-01,  8.4000e-01,  8.6000e-01,  8.8000e-01,\n","         9.0000e-01,  9.2000e-01,  9.4000e-01,  9.6000e-01,  9.8000e-01,\n","         1.0000e+00], dtype=torch.float64)"]},"metadata":{},"execution_count":3}],"source":["# Discritize the interval\n","a = -1\n","b = 1\n","step = (b-a)/100\n","x_init_np = np.arange(start=a, stop=b+step, step=step)\n","x_init = torch.tensor(x_init_np, requires_grad= False)\n","one_init = x_init/x_init\n","one_init\n","x_init"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pxN0oTjcd76g","outputId":"20b61f5c-55d6-4862-9b25-c6a86aeea1e2","executionInfo":{"status":"ok","timestamp":1644904456718,"user_tz":-60,"elapsed":403,"user":{"displayName":"Thu Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64","userId":"04714273295929622355"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Sequential(\n","  (0): Linear(in_features=1, out_features=16, bias=True)\n","  (1): Tanh()\n","  (2): Linear(in_features=16, out_features=16, bias=True)\n","  (3): Tanh()\n","  (4): Linear(in_features=16, out_features=16, bias=True)\n","  (5): Tanh()\n","  (6): Linear(in_features=16, out_features=1, bias=True)\n","  (7): Tanh()\n",")\n"]}],"source":["input_size = 1\n","output_size = 1\n","k = 16\n","\n","model = nn.Sequential(nn.Linear(input_size, k),\n","                      nn.Tanh(),\n","\n","                      nn.Linear(k, k),\n","                      nn.Tanh(),\n","\n","                      nn.Linear(k, k),\n","                      nn.Tanh(),\n","\n","                      nn.Linear(k, output_size),\n","                      nn.Tanh(),\n","\n","                      )\n","print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y21HCpj9Itcd"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","def draw_result(lst_iter, lst_loss, title='Loss'):\n","    plt.plot(lst_iter, lst_loss, '-b', label='loss')\n","    \n","    plt.xlabel(\"n iteration\")\n","    plt.legend(loc='upper left')\n","    plt.title(title)\n","\n","    # save image\n","    plt.savefig(title +\".png\")  # should before show method\n","\n","    # show\n","    plt.show()\n","\n","def draw_graph(lst_iter, lst_loss, lst_acc, title):\n","    plt.plot(lst_iter, lst_loss, '-b', label='true')\n","    plt.plot(lst_iter, lst_acc, '-r', label='neural network')\n","\n","    plt.xlabel(\"x\")\n","    plt.legend(loc='upper left')\n","    plt.title(title)\n","\n","    # save image\n","    plt.savefig(title+\".png\")  # should before show method\n","\n","    # show\n","    plt.show()"]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"_KnInYnLvTcK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7sqtXd41_1KQ"},"outputs":[],"source":["def run_train(lr = 0.001, num_e = 1000):\n","    # optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    time0 = time()\n","    num_e = num_e\n","    iter = []\n","    test_error_vec = []\n","    # print(model.parameters())\n","    scheduler1 = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.1)\n","    scheduler2 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,80], gamma=0.1)\n","    for e in range(num_e):\n","        running_loss = 0\n","        \n","        optimizer.zero_grad() # call zero_Grad\n","        \n","        u_hat = torch.tensor(np.array([]))\n","        for x in x_init_np:\n","            x_tensor = torch.tensor(np.array([x]), requires_grad= True)\n","            temp = model(x_tensor.float())\n","            u_hat = torch.hstack([u_hat, temp])\n","\n","        loss = (u_hat[0]**2 + u_hat[-1]**2 )/2.\n","\n","        d1u_hat = u_hat.clone()  \n","        d1u_hat[0] = 0. #assign like this instead of u_hat[0] = 0 to avoid inplace error by pytorch backprop\n","        d1u_hat[-1] = 0.\n","        d1u_hat[1:-1] = (-u_hat[0:-2] + u_hat[2:])/(2*step)\n","        # d1u_hat[1:-1] = (u_hat[2:] - u_hat[1:-1])/(step)\n","        \n","        d2u_hat = u_hat.clone()    \n","        d2u_hat[1:-1] = (u_hat[0:-2] + u_hat[2:] - 2*u_hat[1:-1])/step**2     \n","        \n","        # loss and backward\n","        loss += torch.mean(((d1u_hat[1:-1])**2- one_init[1:-1])**2) \n","        print(loss)\n","        loss.backward()\n","\n","        optimizer.step() \n","\n","        running_loss += loss.clone().item()    \n","        if (e % 50 == 0):\n","            print(f\"The running loss at {e+1} iteration is: {running_loss}\")\n","        test_error_vec.append(running_loss)\n","        iter.append(e)\n","\n","    draw_result(iter, test_error_vec)\n","    # print(f\"The running loss at {num_e} iteration is: {test_error_vec[-1]}\")\n","    y_true = u_star_func(x_init_np)\n","    draw_graph(x_init_np, y_true, u_hat.clone().detach().numpy(), 'Solutions')\n","    print(np.mean(np.square(y_true -  u_hat.clone().detach().numpy())))       "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"X9jY6HPzTpJC","outputId":"7113af53-c242-499e-9dcf-8257a5f6b862","executionInfo":{"status":"ok","timestamp":1644904722216,"user_tz":-60,"elapsed":265500,"user":{"displayName":"Thu Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64","userId":"04714273295929622355"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","tensor(0.0575, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0566, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0555, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 101 iteration is: 0.055483297100910926\n","tensor(0.0545, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0536, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0526, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0516, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0508, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0498, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0489, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0482, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0474, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0466, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0460, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0453, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0447, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0441, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0435, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0430, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0424, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0419, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0413, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0408, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0403, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0399, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0394, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0389, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0385, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0381, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0376, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0372, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0368, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0364, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0360, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0356, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0352, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0349, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0345, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0342, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0341, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0343, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0354, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0391, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0475, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0552, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0470, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0325, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0403, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0474, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0349, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0332, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0414, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0343, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 151 iteration is: 0.034268722273017714\n","tensor(0.0310, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0371, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0324, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0306, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0347, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0304, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0298, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0327, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0292, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0292, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0310, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0282, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0286, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0296, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0274, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0280, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0286, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0269, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0273, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0277, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0265, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0267, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0270, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0260, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0261, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0264, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0257, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0255, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0258, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0253, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0250, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0252, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0250, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0246, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0247, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0247, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0243, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0242, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0243, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0241, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0239, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0239, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0238, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0236, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0235, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0234, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0234, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0232, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0231, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0230, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 201 iteration is: 0.023030788300085987\n","tensor(0.0229, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0228, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0227, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0226, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0226, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0224, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0223, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0223, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0222, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0221, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0220, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0219, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0218, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0218, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0217, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0216, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0215, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0214, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0214, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0213, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0212, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0211, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0210, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0210, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0209, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0208, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0207, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0207, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0206, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0205, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0205, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0204, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0203, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0202, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0202, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0201, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0200, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0200, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0199, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0198, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0198, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0197, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0197, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0196, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0196, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0196, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0196, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0198, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0202, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0210, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 251 iteration is: 0.021035781402754767\n","tensor(0.0228, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0262, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0317, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0369, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0364, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0263, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0191, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0229, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0304, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0308, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0218, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0193, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0253, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0262, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0202, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0196, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0250, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0243, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0195, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0199, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0237, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0207, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0185, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0204, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0213, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0186, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0184, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0198, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0188, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0179, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0187, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0189, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0177, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0180, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0185, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0180, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0175, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0180, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0180, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0174, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0174, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0177, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0175, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0171, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0173, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0173, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0171, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0169, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0171, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0170, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 301 iteration is: 0.01700279543381245\n","tensor(0.0168, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0168, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0169, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0168, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0166, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0166, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0166, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0166, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0165, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0165, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0164, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0164, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0163, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0163, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0163, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0162, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0161, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0161, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0161, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0161, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0160, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0160, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0159, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0159, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0159, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0158, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0158, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0157, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0157, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0157, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0156, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0156, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0156, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0155, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0155, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0154, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0154, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0154, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0153, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0153, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0153, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0152, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0152, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0152, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0151, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0151, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0151, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0150, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0150, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0150, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 351 iteration is: 0.014959558011315675\n","tensor(0.0149, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0149, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0149, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0148, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0148, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0148, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0147, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0147, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0147, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0146, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0146, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0146, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0145, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0145, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0145, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0144, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0144, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0144, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0144, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0143, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0143, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0143, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0142, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0142, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0142, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0142, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0141, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0141, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0141, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0140, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0140, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0140, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0140, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0140, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0141, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0144, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0150, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0162, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0187, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0231, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0298, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0356, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0337, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0218, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0138, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0181, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 401 iteration is: 0.018125411430672325\n","tensor(0.0275, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0287, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0186, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0143, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0199, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0224, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0160, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0142, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0184, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0195, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0144, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0151, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0184, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0169, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0134, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0161, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0174, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0148, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0137, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0167, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0155, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0135, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0145, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0158, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0135, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0147, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0142, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0131, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0137, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0141, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0132, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0131, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0136, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0133, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0128, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0132, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0132, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0129, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0128, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0131, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0129, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0127, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0128, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0129, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0127, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0126, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0127, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0127, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0125, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 451 iteration is: 0.012540890018917977\n","tensor(0.0126, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0126, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0125, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0125, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0125, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0125, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0123, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0123, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0123, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0123, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0123, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0122, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0122, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0122, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0122, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0122, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0122, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0121, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0121, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0121, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0121, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0121, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0120, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0120, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0120, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0120, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0120, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0120, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0119, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0119, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0119, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0119, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0119, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0119, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0119, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 501 iteration is: 0.01168255370384151\n","tensor(0.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0116, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0116, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0116, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0116, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0116, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0116, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0116, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 551 iteration is: 0.011026070365348622\n","tensor(0.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0123, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0144, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0189, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0280, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0412, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0492, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0343, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0131, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0168, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0371, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0414, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0181, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0164, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0285, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 601 iteration is: 0.028459780249224506\n","tensor(0.0207, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0125, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0248, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0282, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0127, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0249, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0279, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0171, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0201, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0262, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0155, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0189, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0198, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0180, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0145, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0126, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0150, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0134, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0126, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0154, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0134, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0125, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0126, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0116, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0122, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0106, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0104, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0104, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0105, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0106, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0104, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0105, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0105, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0103, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0105, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 651 iteration is: 0.010453453682860674\n","tensor(0.0103, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0103, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0104, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0103, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0103, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0103, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0103, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0103, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0103, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 701 iteration is: 0.009896407098582985\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 751 iteration is: 0.009584236741006103\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 801 iteration is: 0.009319416128547683\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 851 iteration is: 0.009091511764403629\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 901 iteration is: 0.008892978100076356\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 951 iteration is: 0.008718355728934663\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0187, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0265, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0346, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0366, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0247, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0103, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0203, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0282, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0220, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0125, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0227, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0245, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0165, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0133, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0134, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0106, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1001 iteration is: 0.00940740738788217\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1051 iteration is: 0.008483968194908915\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1101 iteration is: 0.008342074313833665\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1151 iteration is: 0.008218570391816525\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1201 iteration is: 0.008104345316477756\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1251 iteration is: 0.007997875575940106\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1301 iteration is: 0.009008329867623227\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0121, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0156, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0217, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0281, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0325, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0267, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0145, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0191, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0210, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0140, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0186, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0163, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0147, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0154, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0121, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1351 iteration is: 0.008153950671334767\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1401 iteration is: 0.007747782916171194\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1451 iteration is: 0.007664872425853637\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1501 iteration is: 0.0075905844580668996\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1551 iteration is: 0.007639137308850414\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1601 iteration is: 0.007459969714030687\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1651 iteration is: 0.007395381998718967\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0130, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0160, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0194, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0214, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0201, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0152, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0132, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1701 iteration is: 0.010135002313864641\n","tensor(0.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1751 iteration is: 0.007290741769650315\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1801 iteration is: 0.00721915646307261\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1851 iteration is: 0.007312295531793661\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1901 iteration is: 0.007122445446729181\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0106, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0127, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0131, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0133, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0121, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0105, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 1951 iteration is: 0.0071232375237637955\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2001 iteration is: 0.006984460319241614\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0105, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2051 iteration is: 0.009064968698049588\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2101 iteration is: 0.006888949297280039\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0129, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0146, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0136, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2151 iteration is: 0.00739056598099558\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2201 iteration is: 0.00676541646242321\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2251 iteration is: 0.0074609477731785185\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2301 iteration is: 0.006679139312070978\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0110, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0120, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0115, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0105, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2351 iteration is: 0.0065724716777801045\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2401 iteration is: 0.006479941426551967\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0131, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0127, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0137, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0143, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0137, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0137, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0103, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2451 iteration is: 0.006813550300993489\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2501 iteration is: 0.006342468828408386\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0116, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0142, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0149, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0161, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0136, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2551 iteration is: 0.010838455688686612\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2601 iteration is: 0.006187059114271131\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2651 iteration is: 0.006101488925214492\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0116, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2701 iteration is: 0.006392164465689306\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2751 iteration is: 0.005940476334352498\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0104, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0120, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0130, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0138, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0126, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2801 iteration is: 0.006072640186220328\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2851 iteration is: 0.005750205872255983\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0141, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0137, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0134, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2901 iteration is: 0.00585353418220366\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 2951 iteration is: 0.00561914237185777\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0148, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0189, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0184, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0160, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3001 iteration is: 0.005505484247977498\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3051 iteration is: 0.005322846373529516\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0111, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0134, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0200, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0191, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0198, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0138, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0112, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0102, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0076, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3101 iteration is: 0.0061921412556348015\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3151 iteration is: 0.005142237805132194\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3201 iteration is: 0.00917299804405693\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0106, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0120, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0145, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0176, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0158, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3251 iteration is: 0.005180767311137641\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3301 iteration is: 0.004840312373141446\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0150, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0181, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0172, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3351 iteration is: 0.004895355851666861\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3401 iteration is: 0.004709827288092679\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3451 iteration is: 0.006293300555784878\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3501 iteration is: 0.004644228570048863\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3551 iteration is: 0.009200191726918125\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3601 iteration is: 0.004466724837367903\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0107, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0116, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3651 iteration is: 0.004590348915554406\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3701 iteration is: 0.004449634747596905\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0068, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3751 iteration is: 0.009233077578661817\n","tensor(0.0097, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0084, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3801 iteration is: 0.004326451882329728\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0104, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0117, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0127, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0120, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0072, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3851 iteration is: 0.007191079696811295\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3901 iteration is: 0.004244886481712469\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 3951 iteration is: 0.004187606495642546\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0077, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0103, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4001 iteration is: 0.004483831067310696\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4051 iteration is: 0.004122917716193587\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0066, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4101 iteration is: 0.004287180807636341\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4151 iteration is: 0.004104725856460485\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0080, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0064, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4201 iteration is: 0.0042848538683277985\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4251 iteration is: 0.004056440808177664\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0099, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0098, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0094, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4301 iteration is: 0.004073170330652662\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4351 iteration is: 0.003983121250985414\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0090, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0113, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0124, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0137, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0067, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4401 iteration is: 0.004073497778562624\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4451 iteration is: 0.00434175897424062\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0056, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4501 iteration is: 0.0039284460470911334\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0055, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0079, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0078, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0058, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4551 iteration is: 0.005441207544136472\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4601 iteration is: 0.003912839148816077\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4651 iteration is: 0.0040218980071478\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0070, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0075, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0083, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4701 iteration is: 0.003927757235411037\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4751 iteration is: 0.0038842406212344686\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0052, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0073, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0085, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0092, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0100, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0086, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0069, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4801 iteration is: 0.00399946320153656\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0047, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0049, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0042, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4851 iteration is: 0.004106375729162993\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4901 iteration is: 0.003998092817009802\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0060, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0091, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0109, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0135, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0139, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0130, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0096, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0061, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0082, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0053, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0057, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0048, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0044, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0041, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0040, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","The running loss at 4951 iteration is: 0.0038704416490211017\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n","tensor(0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["0.00013628851013189368\n","Time = 265.5853500366211\n"]}],"source":["def u_star_func(x):\n","    x = x[1:-1]\n","    result = 1-np.abs(x) # -1+np.abs(x) #+ eps*(np.exp(-1/eps) - np.exp(-1/eps*np.abs(x)))\n","    return np.hstack((0,result,0))\n","time0 = time()\n","run_train(lr=0.01, num_e= 5000)\n","print(f\"Time = {time() - time0}\")"]},{"cell_type":"code","source":["1.36*1e-4 -0.00013628851013189368"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbNOXK-H_RBE","executionInfo":{"status":"ok","timestamp":1644905198242,"user_tz":-60,"elapsed":4,"user":{"displayName":"Thu Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64","userId":"04714273295929622355"}},"outputId":"15ef713b-2483-4e71-84b8-968bab3e0b28"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-2.8851013189365817e-07"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["## plot"],"metadata":{"id":"4l2GR5V9wWbe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDTic9mj5Xec"},"outputs":[],"source":["def evaluate_np(x_data_np):\n","    u_hat = []\n","    for x in x_data_np:\n","        x_tensor = torch.tensor(np.array([x]), requires_grad= True)\n","        temp = model(x_tensor.float())\n","        u_hat.append(temp.clone().item())\n","        # u_hat = torch.hstack([u_hat, temp])\n","    return u_hat"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9uoUTEaZ7DJz"},"outputs":[],"source":["def evaluate_error_np(x_data_np):\n","    y_pred = evaluate_np(x_data_np)\n","    y_true = u_star_func(x_data_np)\n","    return np.mean(np.square(y_true -  y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ao8tXm5RzxVF"},"outputs":[],"source":["# Discritize the interval\n","a = 0\n","b = 1\n","step = (b-a)/100\n","x_init_np = np.arange(start=a, stop=b+step, step=step)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EQ7z_1NV4_LG","colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"status":"ok","timestamp":1644904723023,"user_tz":-60,"elapsed":815,"user":{"displayName":"Thu Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64","userId":"04714273295929622355"}},"outputId":"85a5eec6-c6a4-49c9-9c6f-dd79f62de3af"},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"execute_result","data":{"text/plain":["0.0009819712237057136"]},"metadata":{},"execution_count":11}],"source":["x_init_np2 = np.arange(start=a, stop=b+step/10, step=step/10)\n","x_init2 = torch.tensor(x_init_np2, requires_grad= True)\n","# print(x_init)\n","# print(x_init2.shape)\n","y_pred2 = evaluate_np(x_init_np2)\n","\n","draw_result(x_init_np2, y_pred2, 'solution-NN')\n","evaluate_error_np(x_init_np2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fc5-liOp8099"},"outputs":[],"source":["step_size = []\n","error = []\n","for k in [4,6,8,10,12, 14, 26]:\n","    x_vec = np.arange(start=a, stop=b+step/k, step=step/k)\n","    # x_vec_tensor = torch.tensor(x_vec, requires_grad= True)\n","    y_pred = evaluate_np(x_vec)\n","    error.append(evaluate_error_np(x_vec))\n","    step_size.append(step/k)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"erpPFfAS9-jC","colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"status":"ok","timestamp":1644904727848,"user_tz":-60,"elapsed":493,"user":{"displayName":"Thu Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64","userId":"04714273295929622355"}},"outputId":"7adf5a31-711d-41dd-9ad4-9bb4b81b62fc"},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["[0.0025, 0.0016666666666666668, 0.00125, 0.001, 0.0008333333333333334, 0.0007142857142857143, 0.0003846153846153846]\n"]}],"source":["draw_result(step_size[::-1], error[::-1], 'error')\n","print(step_size)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Eikonal_1D.ipynb","provenance":[{"file_id":"1xiQseJbpEbpZeWvqtTP6EOYs4k0iuT2E","timestamp":1644904367008}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}